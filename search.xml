<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[UFLDL Tutorial 学习笔记]]></title>
    <url>%2F2019%2F05%2F16%2FUFLDL_Tutorial%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Sparse AutoencoderNeural NetworksBackpropagation Algorithm 权重衰减(weight decay)实际上是贝叶斯规则化方法的变种(采用的是最大后验概率估计而不是极大似然估计) 权重衰减的时候并不考虑偏置项$b$ 训练神经网络刚开始的时候，我们需要将每一个参数初始化为一个很小的、接近0的随机值(比如正态分布) 初始化不能全部初始化为0，因为会导致同一层的激活值一样(即对于所有的$i$，$W_{ij}^{(1)}$都会取相同的值，会导致$a_1^{(2)}=a_2^{(2)}=a_3^{(2)}=……​$) Gradient checking and advanced optimizationAutoencoders and Sparsity 自编码神经网络尝试学习一个$f(\hat x ) \approx x$的函数，即尝试去逼近一个恒等函数 自编码网络可以用来学习数据的压缩表示，比如输入层100个神经元，隐层50个神经元，输出层100个神经元，那么该网络就被迫学习一个将100维压缩到50维之后还能还原回原来数据的一个压缩表示 稀疏性限制：如果激活值接近1那么我们认为该神经元激活，接近0那么我们认为该神经元抑制；那么大多数神经元都是处于抑制状态就被称为稀疏性限制 我们希望每个神经元的平均激活度都接近一个常数$\rho​$（如$\rho=0.05​$）（平均是针对一个batch，该神经元的激活值来看的），于是给目标函数还要加上一个稀疏性惩罚：$J_{\text { sparse }}(W, b)=J(W, b)+\beta \sum_{j=1}^{s_{2}} KL\left(\rho | \hat{\rho}_{j}\right)​$ $\sum_{j=1}^{s_2} KL(\rho | \hat{\rho}{j}) = \sum{j=1}^{s_2} \log \frac {\rho}{\hat{\rho}_j}+(1-\rho) \log \frac{1-\rho}{1-\hat{\rho}_j} $ Visualizing a Trained Autoencoder我们考察每一个神经元，可视化它识别了什么特征，这等价于我们要设计输入$x​$，使得其激活值最大。 $$a_{i}^{(2)}=f\left(\sum_{j=1}^{100} W_{i j}^{(1)} x_{j}+b_{i}^{(1)}\right)​$$ 上式就是其激活值。 我们需要给其加约束，否则会得到平凡解。我们要求满足$| | x| |^{2}=\sum_{i=1}^{100} x_{i}^{2} \leq 1$。由拉格朗日乘子法可以得到取最大值时候的闭解：$x_{j}=\frac{W_{i j}^{(1)}}{\sqrt{\sum_{j=1}^{100}\left(W_{i j}^{(1)}\right)^{2}}}$ 于是这样的$x​$就是该神经元识别的特征，如果是图片像素，可以将其展示如下： Vectorized implementationPreprocessing: PCA and WhiteningSoftmax RegressionSelf-Taught Learning and Unsupervised Feature LearningBuilding Deep Networks for ClassificationLinear Decoders with AutoencodersWorking with Large ImagesSummary]]></content>
      <categories>
        <category>Deep Learing</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F01%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 中文测试测试]]></content>
      <categories>
        <category>1</category>
        <category>2</category>
      </categories>
      <tags>
        <tag>其它</tag>
      </tags>
  </entry>
</search>
